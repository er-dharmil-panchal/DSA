# ðŸ§  **Time and Space Complexity (Basic)**

---

## â±ï¸ **Time Complexity**

### ðŸ”¹ What is Time Complexity?
> Time Complexity is the rate at which the **execution time** of an algorithm increases with respect to the **input size (N)**.

âš ï¸ **Note:**  
> **Time Complexity â‰  Actual Time Taken**  
> It tells us how the runtime **grows** as the input size increases â€” not the actual time in seconds.

---

### ðŸ”¹ Notation â€” **Big O**
We use **Big O Notation (O)** to describe the **upper bound (worst-case growth rate)** of an algorithmâ€™s growth rate.  
It helps us compare algorithms regardless of hardware or language.

ðŸ“˜ **Quick Summary of Notations:**
- **Big-O (O)** â†’ Upper Bound â†’ *Worst Case*
- **Theta (Î˜)** â†’ Tight Bound â†’ *Average Case*
- **Omega (Î©)** â†’ Lower Bound â†’ *Best Case*
---

### ðŸ”¹ Rules to Remember

#### ðŸ§© 1. Always consider the **worst-case scenario**
Compute time complexity for the most time-consuming input.

Example:
```java
if (marks < 20) {
    System.out.println("D");
}
else if (marks < 45) {
    System.out.println("C");
}
else if (marks < 65) {
    System.out.println("B");
}
else {
    System.out.println("A");
}
```
> **Best Case:** `marks = 10` â†’ Executes only the first condition â†’ **O(1)**  
> **Worst Case:** `marks = 70` â†’ Checks all conditions one by one â†’ **O(4)** â†’ Simplifies to **O(1)** âœ…  
> Because constants are ignored in time complexity (explained below).

---

### ðŸ§© 2 & 3. Ignore Constants & Focus on the Dominant Term
- When we calculate time complexity, constant factors donâ€™t matter.
- Only the term that grows the fastest (highest power of `N`) is considered.

Example: **O(3NÂ³ + 2NÂ² + 8) â†’ O(NÂ³)**


âœ… **Why?**  
Because as `N` becomes large, the impact of smaller terms and constants becomes negligible.

---

### ðŸ’¡ Common Examples

| Code Snippet | Time Complexity | Explanation |
|---------------|-----------------|--------------|
| `for (int i = 0; i < N; i++)` | **O(N)** | Runs N times |
| Two nested loops (`for` inside `for`) | **O(NÂ²)** | N Ã— N iterations |
| Constant statements (no loops) | **O(1)** | Executes once |

---
---
---

## ðŸ§® **Space Complexity**

---

### ðŸ”¹ What is Space Complexity?

> Space Complexity is the **total memory space** your program requires during execution.

It also follows **Big-O notation**, just like Time Complexity.

---

### ðŸ”¹ Definition

> **Space Complexity = Auxiliary Space + Input Space**

| Term | Meaning |
|------|----------|
| **Auxiliary Space** | The extra or temporary space used to solve the problem (e.g., variables, recursion stack). |
| **Input Space** | The memory required to store the input data itself. |

---

### ðŸ§© Examples

#### âœ… Example 1:
```java
int a, b, c;
c = a + b;
```
âž¡ï¸ Uses only fixed number of variables â†’ **O(1)** space (constant).

---

#### âœ… Example 2:
```java
int arr[] = new int[n];
```
âž¡ï¸ Creates an array of size `n` â†’ **O(n)** space (linear).

---

### ðŸ§  Notes
- Space complexity measures **memory**, not **speed**.  
- Just like time complexity, we **ignore constants** and focus on **dominant terms**.  
- Recursive functions also take **extra stack space** depending on the depth of recursion.

---

### ðŸ’¡ Common Space Complexities

| Code / Structure | Space Complexity | Description |
|------------------|------------------|--------------|
| Simple variables | **O(1)** | Constant memory |
| Array of size N | **O(N)** | Linear memory |
| 2D matrix (NÃ—N) | **O(NÂ²)** | Quadratic memory |
| Recursive call depth N | **O(N)** | Stack space usage |

---

### âš–ï¸ **Time vs Space Complexity**

| Aspect | Time Complexity | Space Complexity |
|---------|------------------|------------------|
| **Meaning** | Measures how fast the program runs | Measures how much memory it uses |
| **Goal** | Reduce number of operations | Reduce extra memory usage |
| **Notation** | Big-O (O), Theta (Î˜), Omega (Î©) | Big-O (O), Theta (Î˜), Omega (Î©) |
| **Example** | `for` loop â†’ O(N) | array[N] â†’ O(N) |
| **Trade-off** | Often faster algorithms use more space | Memory-efficient algorithms may run slower |

---

âœ… **Key Takeaway:**  
> Space Complexity = Memory used to **store input + solve the problem**  
> Always aim for minimal **auxiliary space** while balancing **time efficiency**.

